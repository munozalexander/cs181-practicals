{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...       0.0       0.0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...       1.0       0.0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...       1.0       0.0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...       1.0       0.0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1       0.0       0.0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \\\n",
       "0       0.0       0.0       1.0       0.0       1.0       0.0       0.0   \n",
       "1       0.0       0.0       1.0       0.0       1.0       0.0       0.0   \n",
       "2       0.0       0.0       1.0       1.0       1.0       0.0       0.0   \n",
       "3       0.0       0.0       1.0       1.0       1.0       0.0       0.0   \n",
       "4       0.0       0.0       1.0       0.0       1.0       0.0       0.0   \n",
       "\n",
       "     ...     feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  \\\n",
       "0    ...          0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "1    ...          0.0       1.0       0.0       0.0       1.0       0.0   \n",
       "2    ...          0.0       1.0       0.0       0.0       0.0       1.0   \n",
       "3    ...          0.0       1.0       0.0       0.0       0.0       1.0   \n",
       "4    ...          0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   feat_253  feat_254  feat_255  feat_256  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\"train.csv.gz\")\n",
    "df_test = pd.read_csv(\"test.csv.gz\")\n",
    "test_idx = df_train.shape[0]\n",
    "df_train_gap = df_train.gap\n",
    "df_test_ids = df_test.Id\n",
    "df_train = df_train.drop(['gap'], axis=1)\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert SMILES strings to integer arrays\n",
    "smiles = list(df_train.smiles) + list(df_test.smiles)\n",
    "tokenizer = text.Tokenizer(filters='', lower=False, char_level=True)\n",
    "tokenizer.fit_on_texts(smiles)\n",
    "smile_nums = tokenizer.texts_to_sequences(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Length:  22 \n",
      "Avg Length:  50.7 \n",
      "Max Length:  81\n"
     ]
    }
   ],
   "source": [
    "# print SMILES sizes\n",
    "lens = [len(a) for a in smile_nums]\n",
    "print \"Min Length: \", min(lens), \"\\nAvg Length: \", round(np.mean(lens),1), \"\\nMax Length: \", max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "smile_nums = smile_nums[:test_idx]\n",
    "smile_test = smile_nums[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator for data\n",
    "def batch_generator(batch_samples, num_batches, window_size=20):\n",
    "    for batch_num in range(num_batches):\n",
    "        X_batch, y_batch = [], []\n",
    "        for e,smile_num in enumerate(smile_nums[batch_num*batch_samples:(batch_num+1)*batch_samples]):\n",
    "            for i in range(len(smile_num)-window_size):\n",
    "                X_batch.append(smile_num[i:i+window_size])\n",
    "                y_batch.append(df_train_gap[e])\n",
    "        X_batch, y_batch = np.array(X_batch), np.array(y_batch)\n",
    "        X_batch = np_utils.to_categorical(X_batch)\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               284672    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 288,801\n",
      "Trainable params: 288,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "window_size = 20\n",
    "num_chars = len(chars2idx.keys())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(window_size, num_chars)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPOCH:  1 / 1\n",
      "Train on 23148 samples, validate on 7716 samples\n",
      "Epoch 1/1\n",
      "23148/23148 [==============================] - 53s 2ms/step - loss: 0.1363 - val_loss: 0.1794\n",
      "Train on 23022 samples, validate on 7674 samples\n",
      "Epoch 1/1\n",
      "23022/23022 [==============================] - 52s 2ms/step - loss: 0.1718 - val_loss: 0.1982\n",
      "Train on 22804 samples, validate on 7602 samples\n",
      "Epoch 1/1\n",
      "22804/22804 [==============================] - 51s 2ms/step - loss: 0.1691 - val_loss: 0.1865\n",
      "Train on 22859 samples, validate on 7620 samples\n",
      "Epoch 1/1\n",
      "22859/22859 [==============================] - 50s 2ms/step - loss: 0.1664 - val_loss: 0.1789\n",
      "Train on 23196 samples, validate on 7733 samples\n",
      "Epoch 1/1\n",
      "23196/23196 [==============================] - 53s 2ms/step - loss: 0.1685 - val_loss: 0.1930\n",
      "Train on 23313 samples, validate on 7772 samples\n",
      "Epoch 1/1\n",
      "23313/23313 [==============================] - 52s 2ms/step - loss: 0.1677 - val_loss: 0.1865\n",
      "Train on 22879 samples, validate on 7627 samples\n",
      "Epoch 1/1\n",
      "22879/22879 [==============================] - 51s 2ms/step - loss: 0.1696 - val_loss: 0.1924\n",
      "Train on 23000 samples, validate on 7667 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 52s 2ms/step - loss: 0.1694 - val_loss: 0.1899\n",
      "Train on 23166 samples, validate on 7723 samples\n",
      "Epoch 1/1\n",
      "23166/23166 [==============================] - 52s 2ms/step - loss: 0.1688 - val_loss: 0.1864\n",
      "Train on 22907 samples, validate on 7636 samples\n",
      "Epoch 1/1\n",
      "22907/22907 [==============================] - 52s 2ms/step - loss: 0.1678 - val_loss: 0.1912\n",
      "Train on 22970 samples, validate on 7657 samples\n",
      "Epoch 1/1\n",
      "22970/22970 [==============================] - 52s 2ms/step - loss: 0.1659 - val_loss: 0.1977\n",
      "Train on 23004 samples, validate on 7668 samples\n",
      "Epoch 1/1\n",
      "23004/23004 [==============================] - 54s 2ms/step - loss: 0.1679 - val_loss: 0.1925\n",
      "Train on 22970 samples, validate on 7657 samples\n",
      "Epoch 1/1\n",
      "22970/22970 [==============================] - 52s 2ms/step - loss: 0.1666 - val_loss: 0.1895\n",
      "Train on 22981 samples, validate on 7661 samples\n",
      "Epoch 1/1\n",
      "22981/22981 [==============================] - 52s 2ms/step - loss: 0.1669 - val_loss: 0.1993\n",
      "Train on 22968 samples, validate on 7657 samples\n",
      "Epoch 1/1\n",
      "22968/22968 [==============================] - 53s 2ms/step - loss: 0.1672 - val_loss: 0.1942\n",
      "Train on 22812 samples, validate on 7605 samples\n",
      "Epoch 1/1\n",
      "22812/22812 [==============================] - 53s 2ms/step - loss: 0.1662 - val_loss: 0.1846\n",
      "Train on 23071 samples, validate on 7691 samples\n",
      "Epoch 1/1\n",
      "23071/23071 [==============================] - 54s 2ms/step - loss: 0.1679 - val_loss: 0.1887\n",
      "Train on 22955 samples, validate on 7652 samples\n",
      "Epoch 1/1\n",
      "22955/22955 [==============================] - 53s 2ms/step - loss: 0.1658 - val_loss: 0.1936\n",
      "Train on 22735 samples, validate on 7579 samples\n",
      "Epoch 1/1\n",
      "22735/22735 [==============================] - 55s 2ms/step - loss: 0.1685 - val_loss: 0.1891\n",
      "Train on 22788 samples, validate on 7596 samples\n",
      "Epoch 1/1\n",
      "22788/22788 [==============================] - 53s 2ms/step - loss: 0.1674 - val_loss: 0.2008\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "nb_epoch = 1\n",
    "loss, val_loss = [], []\n",
    "for e in range(nb_epoch):\n",
    "    print \"\\n\\nEPOCH: \", e+1, \"/\", nb_epoch\n",
    "    for X_batch, y_batch in batch_generator(batch_samples=1000, num_batches=20): \n",
    "        history = model.fit(X_batch, y_batch, batch_size=32, epochs=1, validation_split=.25)\n",
    "        loss.append(history.history['loss'])\n",
    "        val_loss.append(history.history['val_loss'])\n",
    "model.save('lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test set generator\n",
    "def test_generator(window_size=20):\n",
    "    for smile in smile_test:\n",
    "        dataX = [smile[i:i+window_size] for i in range(len(smile)-window_size)]\n",
    "        yield dataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_1_input to have shape (None, 20, 21) but got array with shape (31, 20, 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fd2dd0ccaaa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msmile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/MacBookAir/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MacBookAir/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1764\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MacBookAir/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_1_input to have shape (None, 20, 21) but got array with shape (31, 20, 19)"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = [np.median(model.predict(smile)) for smile in test_generator()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")\n",
    "            \n",
    "write_to_file('Predictions/test.csv', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
